{\rtf1\ansi\ansicpg1252\cocoartf2821
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 HelveticaNeue-Bold;\f1\fswiss\fcharset0 ArialMT;}
{\colortbl;\red255\green255\blue255;\red14\green18\blue30;\red247\green249\blue250;}
{\*\expandedcolortbl;;\cssrgb\c6275\c9412\c15686;\cssrgb\c97647\c98039\c98431;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10600\viewh16080\viewkind0
\deftab560
\pard\pardeftab560\partightenfactor0

\f0\b\fs40 \cf0 Linear Algebra 2\

\fs26 \
Weight vector:\
Weight is 
\f1\b0\fs32 \AppleTypeServices\AppleTypeServicesF65539 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Think about how we might want to give different importance to different components in a system.\
\
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 Let me try a simple analogy. Think of grading a test - some questions are worth more points (have more "weight") than others. Similarly, in a weight vector, each component has a value that shows how important or influential it is. Would you like me to explain how this connects to machine learning or data analysis?\
\
Think of a house price prediction. What features might affect the price? Like size, location, etc. The weight vector tells us HOW MUCH each feature matters. A higher weight means that feature has more influence on the final price.\'a0}