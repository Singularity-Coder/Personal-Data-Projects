{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "789ee582-4e9b-463e-8794-014269b2a5f7",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "Web scraping for academic or personal use as per AI:\n",
    "\n",
    "1. Wikipedia\n",
    "2. Books To Scrape (https://books.toscrape.com/)\n",
    "3. Quotes To Scrape (https://quotes.toscrape.com/)\n",
    "4. Scrape This Site (http://www.scrapethissite.com/)\n",
    "5. IMDb (with restrictions)\n",
    "6. GitHub (public repositories)\n",
    "7. Data.gov\n",
    "8. Craigslist (with limitations)\n",
    "9. Amazon product listings (with restrictions)\n",
    "10. The New York Times Developer Network (with API key)\n",
    "11. OpenStreetMap\n",
    "12. Goodreads (with API)\n",
    "13. National Weather Service\n",
    "1. **Common Crawl** - A public repository of web crawl data that can be freely accessed and used.\n",
    "2. **Wikipedia** - The content is freely available under a Creative Commons license, and scraping is allowed within certain guidelines.\n",
    "3. **OpenWeatherMap** - Provides weather data, and they offer a free tier API which you can scrape with permission.\n",
    "4. **Reddit** - Allows scraping for non-commercial purposes as long as it abides by their API usage policy.\n",
    "5. **Twitter** - Permits scraping through their API for personal use, subject to rate limits.\n",
    "6. **IMDB** - Has a public dataset available for scraping for non-commercial use.\n",
    "7. **GitHub** - Public repositories can be scraped, but there are rate limits and terms of service to consider.\n",
    "8. **News websites with public APIs** - Such as The Guardian and The New York Times, often provide APIs for accessing their data.\n",
    "\n",
    "Before scraping any website:\n",
    "\n",
    "1. Checking the site's robots.txt file\n",
    "2. Reviewing their terms of service\n",
    "3. Using APIs when available\n",
    "4. Respecting rate limits and not overloading servers\n",
    "5. Identifying your scraper in the user-agent string\n",
    "6. Avoid scraping login-protected content or data behind paywalls without permission.\n",
    "7. For academic or research purposes, contacting the website administrators to seek explicit permission is also advisable.\n",
    "\n",
    "Refer\n",
    "* https://en.wikipedia.org/robots.txt\n",
    "* [Google Scholer](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=web+scraping+python&btnG=&oq=web+scraping)\n",
    "\n",
    "Overview\n",
    "* Understanding HTML\n",
    "* Extracting Web Content\n",
    "* Extracting all books from a page\n",
    "* Extracting data of a single book\n",
    "* Fetching the data of all books in one page\n",
    "* Scraping all books from all the pages\n",
    "* Fixing the data formatting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc33bd-7bc8-49c6-b7d5-614138f9a659",
   "metadata": {},
   "source": [
    "### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "11514453-98c5-4a31-aae4-a14056c0b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs # can fetch data from html tags\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e9d50b-d0b9-44bf-8762-78b40c097326",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f19f0710-b140-4c8c-b670-7501d00aad23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Great Gatsby', 'To Kill a Mockingbird', '1984', 'The Testaments', 'Normal People']\n"
     ]
    }
   ],
   "source": [
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Book Store</title>\n",
    "</head>\n",
    "<body>\n",
    "    <div id=\"bestsellers\">\n",
    "        <h2>Best Selling Books</h2>\n",
    "        <ul>\n",
    "            <li><a href=\"/book1\">The Great Gatsby</a></li>\n",
    "            <li><a href=\"/book2\">To Kill a Mockingbird</a></li>\n",
    "            <li><a href=\"/book3\">1984</a></li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div id=\"new-releases\">\n",
    "        <h2>New Releases</h2>\n",
    "        <ul>\n",
    "            <li><a href=\"/book4\">The Testaments</a></li>\n",
    "            <li><a href=\"/book5\">Normal People</a></li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = bs(html_doc, 'html.parser')\n",
    "titles = [a.get_text() for a in soup.find_all('a')]\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be360c-82f2-4866-a0a3-c15979979307",
   "metadata": {},
   "source": [
    "### Get website data\n",
    "1. **200 OK**: The request has been successfully processed, and the server returns the requested content.\n",
    "2. **404 Not Found**: The requested resource or page could not be found on the server.\n",
    "3. **403 Forbidden**: Access to the requested resource is forbidden or not allowed for the client.\n",
    "4. **500 Internal Server Error**: The server encountered an unexpected error while processing the request.\n",
    "5. **302 Found (or 301 Moved Permanently)**: The requested resource has been temporarily (or permanently) moved to a different URL, and the client should follow the redirection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "abbb47b0-7a1c-4617-9678-89bd9d6953ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "url = \"https://books.toscrape.com/\"\n",
    "base_url = \"https://books.toscrape.com/index.html\"\n",
    "book_list = requests.get(base_url)\n",
    "if result.status_code == 200:\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(f\"Failed: {book_list.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bedc7a2-580d-4816-b8d8-397fd0371267",
   "metadata": {},
   "source": [
    "### Verify received data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77a5bb97-a9b9-496a-adda-7e476ad092c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<!--[if lt IE 7]>      <html lang=\"en-us\" class=\"no-js lt-ie9 lt-ie8 lt-ie7\"> <![endif]-->\n",
      "<!--[if IE 7]>         <html lang=\"en-us\" class=\"no-js lt-ie9 lt-ie8\"> <![endif]-->\n",
      "<!--[if IE 8]>         <html lang=\"en-us\" class=\"no-js lt-ie9\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!-->\n",
      "<html class=\"no-js\" lang=\"en-us\">\n",
      " <!--<![endif]-->\n",
      " <head>\n",
      "  <title>\n",
      "   All products | Books to Scrape - Sandbox\n",
      "  </title>\n",
      "  &lt;meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\" /\n",
      " </head>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bs(book_list.content[:500], 'html.parser').prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3f0981-bf1e-4ca6-a313-779634db39e7",
   "metadata": {},
   "source": [
    "### Parse received data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "26e9bc10-214a-4df7-8362-02fb2ad89510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dc9273cf-cd83-42dd-b292-ef5e63ae60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This crawls the html page we downloaded\n",
    "# pass parser = \"html.parser\" if allowed & necessary\n",
    "soup = bs(\n",
    "    markup = book_list.content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "677e2d1f-37d2-4ade-ae19-c7b5d38bfef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "<li class=\"col-xs-6 col-sm-4 col-md-3 col-lg-3\">\n",
      "<article class=\"product_pod\">\n",
      "<div class=\"image_container\">\n",
      "<a href=\"catalogue/tipping-the-velvet_999/index.html\"><img alt=\"Tipping the Velvet\" class=\"thumbnail\" src=\"media/cache/26/0c/260c6ae16bce31c8f8c95daddd9f4a1c.jpg\"/></a>\n",
      "</div>\n",
      "<p class=\"star-rating One\">\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "</p>\n",
      "<h3><a href=\"catalogue/tipping-the-velvet_999/index.html\" title=\"Tipping the Velvet\">Tipping the Velvet</a></h3>\n",
      "<div class=\"product_price\">\n",
      "<p class=\"price_color\">£53.74</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<form>\n",
      "<button class=\"btn btn-primary btn-block\" data-loading-text=\"Adding...\" type=\"submit\">Add to basket</button>\n",
      "</form>\n",
      "</div>\n",
      "</article>\n",
      "</li>\n"
     ]
    }
   ],
   "source": [
    "books = soup.find_all(name = \"li\", class_ = \"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
    "print(len(books))\n",
    "print(books[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c71cc98-a7ad-4c55-823a-d782889e0d37",
   "metadata": {},
   "source": [
    "### Get first book meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f32e767-de83-454e-be68-04f237cbb6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"catalogue/tipping-the-velvet_999/index.html\"><img alt=\"Tipping the Velvet\" class=\"thumbnail\" src=\"media/cache/26/0c/260c6ae16bce31c8f8c95daddd9f4a1c.jpg\"/></a>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for hyperlink tag\n",
    "book_one_anchor = books[1].findChild(\"a\")\n",
    "book_one_anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "de55af39-2c37-4fa9-854a-ca0529d0c445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'catalogue/tipping-the-velvet_999/index.html'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract book detail page end point link\n",
    "book_one_url = book_one_anchor.get(\"href\")\n",
    "book_one_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c1bd54e-061b-4968-8e21-ee7d7e48e065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_one_url = urljoin(base_url, book_one_url)\n",
    "book_one_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72eb25b-f218-48e6-9702-eb427d6815f9",
   "metadata": {},
   "source": [
    "### Get first book HTML code from link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "78db5cfc-933f-4161-bef8-ea9fad68a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract details webpage html data\n",
    "the_book_one_page = requests.get(book_one_url)\n",
    "#print(bs(the_book_one_page.content[6000:len(the_book_one_page.content)], 'html.parser').prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5b473e77-6db1-47c7-8e4a-76546433aeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tipping the Velvet'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_one_soup = bs(markup = the_book_one_page.content)\n",
    "title = book_one_soup.find(\"h1\")\n",
    "title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "49bcd135-dc24-4022-9165-81830e94cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_one_table = book_one_soup.find_all(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9ab7f20b-61e5-4ea6-a0f1-b8c1dff25623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tr>\n",
      "<th>UPC</th><td>90fa61229261140a</td>\n",
      "</tr>, <tr>\n",
      "<th>Product Type</th><td>Books</td>\n",
      "</tr>, <tr>\n",
      "<th>Price (excl. tax)</th><td>£53.74</td>\n",
      "</tr>, <tr>\n",
      "<th>Price (incl. tax)</th><td>£53.74</td>\n",
      "</tr>, <tr>\n",
      "<th>Tax</th><td>£0.00</td>\n",
      "</tr>, <tr>\n",
      "<th>Availability</th>\n",
      "<td>In stock (20 available)</td>\n",
      "</tr>, <tr>\n",
      "<th>Number of reviews</th>\n",
      "<td>0</td>\n",
      "</tr>]\n",
      "\n",
      "<tr>\n",
      "<th>UPC</th><td>90fa61229261140a</td>\n",
      "</tr>\n",
      "\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(book_one_table, end = \"\\n\\n\")\n",
    "print(book_one_table[0], end = \"\\n\\n\") # Key Value Pair\n",
    "print(len(book_one_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "663c39f4-165f-4d74-bdc5-7290d1713063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': <h1>Tipping the Velvet</h1>,\n",
       " 'UPC': '90fa61229261140a',\n",
       " 'Product Type': 'Books',\n",
       " 'Price (excl. tax)': '£53.74',\n",
       " 'Price (incl. tax)': '£53.74',\n",
       " 'Tax': '£0.00',\n",
       " 'Availability': 'In stock (20 available)',\n",
       " 'Number of reviews': '0'}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract data from HTML and add it to dictionary\n",
    "book_one_dict = {\n",
    "    \"Title\" : title\n",
    "}\n",
    "for book in book_one_table:\n",
    "    key = book.find(\"th\").text\n",
    "    value = book.find(\"td\").text\n",
    "    book_one_dict[key] = value\n",
    "\n",
    "book_one_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced23d40-949b-47bb-9173-3e44f114a294",
   "metadata": {},
   "source": [
    "### Create a function to get HTML code from link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5d467a88-fc58-4c94-b32d-6f350b26c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encapsulate all of the above code in a single function\n",
    "# find(), find_all(), select(), select_one()\n",
    "def scrape_book(book_url: str):\n",
    "    book_page = requests.get(book_url)\n",
    "    book_soup = bs(book_page.content)\n",
    "\n",
    "    # store data in dict\n",
    "    book_dict = {}\n",
    "\n",
    "    image = book_soup.find(name = \"div\", class_ = \"item active\").findChild(\"img\").get(\"src\")\n",
    "    title = book_soup.find(\"h1\").text\n",
    "    description = book_soup.find(\"p\").text\n",
    "    book_dict[\"title\"] = title\n",
    "    book_dict[\"image\"] = urljoin(url, image)\n",
    "    # book_dict[\"description\"] = description\n",
    "\n",
    "    book_table_data = book_soup.find_all(\"tr\")\n",
    "\n",
    "    # for product info iterate and get all key-value pairs\n",
    "    for book in book_table_data:\n",
    "        key = book.find(\"th\").text\n",
    "        value = book.find(\"td\").text\n",
    "\n",
    "        book_dict[key] = value\n",
    "\n",
    "    return book_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ca01b6b6-6106-4839-9e07-b8acf646a01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'A Light in the Attic',\n",
       " 'image': 'https://books.toscrape.com/media/cache/fe/72/fe72f0532301ec28892ae79a629a293c.jpg',\n",
       " 'UPC': 'a897fe39b1053632',\n",
       " 'Product Type': 'Books',\n",
       " 'Price (excl. tax)': '£51.77',\n",
       " 'Price (incl. tax)': '£51.77',\n",
       " 'Tax': '£0.00',\n",
       " 'Availability': 'In stock (22 available)',\n",
       " 'Number of reviews': '0'}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the method with dummy url\n",
    "scrape_book(\"http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e5571f-e136-4ae7-b1c3-1c836d675041",
   "metadata": {},
   "source": [
    "### Create a function to scrape the entire webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c8cf9523-3905-407b-a963-687c2e1c3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "e6bab72d-4f2b-4ccd-9482-f45af4996aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(base_url: str):\n",
    "    page = requests.get(base_url)\n",
    "    page_soup = bs(page.content)\n",
    "    \n",
    "    books = page_soup.find_all(name = \"li\", class_ = \"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
    "\n",
    "    for i in range(len(books)):\n",
    "        relative_path = books[i].findChild(\"a\").get(\"href\") # its relative path because the full url is not provided\n",
    "        book_url = urljoin(base_url, relative_path)\n",
    "        book_data = scrape_book(book_url)\n",
    "        book_list.append(book_data)\n",
    "        print(f\"Fetched {i + 1}/{len(books)}\")\n",
    "\n",
    "    next_page_url = page_soup.find(name = \"li\", class_ = \"next\").findChild(\"a\").get(\"href\")\t\n",
    "\n",
    "    # Wait for 1 seconds before making next call\n",
    "    time.sleep(1) \n",
    "\n",
    "    try:\n",
    "        # Recursive call to continuoulsy fetch items from next page until next page doesnt exist\n",
    "        scrape_page(urljoin(base_url, next_page_url))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "345635ad-b177-4cfb-b745-48728d2914f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch all books from all pages\n",
    "scrape_page('http://books.toscrape.com/index.html')\n",
    "len(book_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019b2332-e9ec-4d54-92b3-461c2cf5d514",
   "metadata": {},
   "source": [
    "### Format unstructred data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "c7c9ed09-f682-493d-a69c-65f745e75f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'A Light in the Attic',\n",
       " 'image': 'https://books.toscrape.com/media/cache/fe/72/fe72f0532301ec28892ae79a629a293c.jpg',\n",
       " 'UPC': 'a897fe39b1053632',\n",
       " 'Product Type': 'Books',\n",
       " 'Price (excl. tax)': '£51.77',\n",
       " 'Price (incl. tax)': '£51.77',\n",
       " 'Tax': '£0.00',\n",
       " 'Availability': 'In stock (22 available)',\n",
       " 'Number of reviews': '0'}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "29cf1586-91f8-4fa6-84b3-700047f78993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'A Light in the Attic',\n",
       "  'image': 'https://books.toscrape.com/media/cache/fe/72/fe72f0532301ec28892ae79a629a293c.jpg',\n",
       "  'UPC': 'a897fe39b1053632',\n",
       "  'Product Type': 'Books',\n",
       "  'Tax': 0.0,\n",
       "  'Availability': 'In stock',\n",
       "  'Number of reviews': 0.0,\n",
       "  'Price': 51.77,\n",
       "  'Quantity': 22,\n",
       "  'IsAvailable': True},\n",
       " {'title': 'Tipping the Velvet',\n",
       "  'image': 'https://books.toscrape.com/media/cache/08/e9/08e94f3731d7d6b760dfbfbc02ca5c62.jpg',\n",
       "  'UPC': '90fa61229261140a',\n",
       "  'Product Type': 'Books',\n",
       "  'Tax': 0.0,\n",
       "  'Availability': 'In stock',\n",
       "  'Number of reviews': 0.0,\n",
       "  'Price': 53.74,\n",
       "  'Quantity': 20,\n",
       "  'IsAvailable': True},\n",
       " {'title': 'Soumission',\n",
       "  'image': 'https://books.toscrape.com/media/cache/ee/cf/eecfe998905e455df12064dba399c075.jpg',\n",
       "  'UPC': '6957f44c3847a760',\n",
       "  'Product Type': 'Books',\n",
       "  'Tax': 0.0,\n",
       "  'Availability': 'In stock',\n",
       "  'Number of reviews': 0.0,\n",
       "  'Price': 50.1,\n",
       "  'Quantity': 20,\n",
       "  'IsAvailable': True}]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fix(item: dict):\n",
    "    if isinstance(item.get(\"Price (excl. tax)\"), str):\n",
    "        price = float(item[\"Price (excl. tax)\"][1:])\n",
    "        item[\"Price\"] = price\n",
    "        item.pop(\"Price (excl. tax)\")\n",
    "        if \"Price (incl. tax)\" in item:\n",
    "            item.pop(\"Price (incl. tax)\")\n",
    "        \n",
    "\n",
    "    tax = float(item[\"Tax\"][1:])\n",
    "    item[\"Tax\"] = tax\n",
    "\n",
    "    stuff = item[\"Availability\"].split(\"(\")\n",
    "    availability = stuff[0].strip()\n",
    "    quantity = int(stuff[1].split(\" \")[0])\n",
    "    is_available = True if quantity > 0 else False\n",
    "    item[\"Availability\"] = availability\n",
    "    item[\"Quantity\"] = quantity\n",
    "    item[\"IsAvailable\"] = is_available\n",
    "\n",
    "    item[\"Number of reviews\"] = float(item[\"Number of reviews\"])\n",
    "\n",
    "    return item\n",
    "    \n",
    "formatted_books_list = list(map(lambda x : fix(x), book_list))\n",
    "formatted_books_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc27da2-0e89-4234-84b6-d3ab9af75003",
   "metadata": {},
   "source": [
    "### Export all books to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bf194a97-1a9c-410e-ad9c-588ba4739d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_csv():\n",
    "    # Using \"with\" to open a file automatically handles closing file manager\n",
    "    with open('all_books.csv','w') as f:\n",
    "        # w = csv.writer(sys.stderr) # see whats being generated\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(book.keys())\n",
    "        for book in book_list:\n",
    "            w.writerow(book.values())\n",
    "            \n",
    "    print(f\"all_books.csv downloaded in {os.curdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a469030e-43d1-4604-9bba-7f38a79d4a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dict_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1ec65e-4fe2-4437-ae6d-419b51591c78",
   "metadata": {},
   "source": [
    "### Export all books to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "23b0e59f-0b17-445c-b7b5-ab661850a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_json():\n",
    "    # Convert and write JSON object to file\n",
    "    with open(\"all_books.json\", \"w\") as f: \n",
    "        json.dump(book_list, f)\n",
    "        \n",
    "    print(f\"all_books.json downloaded in {os.curdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e1817-6299-4605-822b-90891c3fb6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dict_to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0737863c-47cf-416c-9cb9-2b413ef1cd53",
   "metadata": {},
   "source": [
    "### Export all books to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c0464b-e47a-4d23-9388-40cebbe8a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_textfile():\n",
    "    with open('all_books.txt', 'w') as f: \n",
    "        f.write(json.dumps(book_list))\n",
    "        \n",
    "    print(f\"all_books.txt downloaded in {os.curdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf774d-8348-4a75-8046-5e6c3e750c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dict_to_textfile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7943db37-3ad0-4087-81ae-8ec684a09c8d",
   "metadata": {},
   "source": [
    "### Download Images of all books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3916dcba-fee1-4879-85e7-803ad4af2972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images():\n",
    "    image_url_list = list(map(lambda x : x[\"image\"], book_list))\n",
    "    \n",
    "    for i in range(len(image_url_list)):\n",
    "        img_data = requests.get(image_url_list[i])\n",
    "        \n",
    "        if img_data.status_code != 200:\n",
    "            print(f\"Failed to download {image_url_list[i]} with error {book_list.status_code}\")\n",
    "            continue\n",
    "            \n",
    "        filename = image_url_list[i].split('/')[-1]\n",
    "\n",
    "        img_dir = \"book_images\"\n",
    "        \n",
    "        if img_dir not in os.listdir(os.curdir):\n",
    "            os.mkdir(img_dir)\n",
    "        \n",
    "        with open(f\"{img_dir}/{filename}\", 'wb') as f:\n",
    "            f.write(img_data.content)\n",
    "        \n",
    "        print(f\"Downloaded image {i + 1}/{len(image_url_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8caa2d07-5adc-4bd3-85b8-28fb6a1b5e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1/20\n",
      "Downloaded 2/20\n",
      "Downloaded 3/20\n",
      "Downloaded 4/20\n",
      "Downloaded 5/20\n",
      "Downloaded 6/20\n",
      "Downloaded 7/20\n",
      "Downloaded 8/20\n",
      "Downloaded 9/20\n",
      "Downloaded 10/20\n",
      "Downloaded 11/20\n",
      "Downloaded 12/20\n",
      "Downloaded 13/20\n",
      "Downloaded 14/20\n",
      "Downloaded 15/20\n",
      "Downloaded 16/20\n",
      "Downloaded 17/20\n",
      "Downloaded 18/20\n",
      "Downloaded 19/20\n",
      "Downloaded 20/20\n"
     ]
    }
   ],
   "source": [
    "download_images()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
